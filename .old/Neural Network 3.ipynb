{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov_P-pFvmxDc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3rQtqsf_0Nm",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install scipy\n",
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install scikit-learn\n",
    "# %pip install statsmodels\n",
    "# %pip install tensorflow\n",
    "# %pip install scikit-survival\n",
    "# %pip install xgboost\n",
    "# %pip install factor-analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "PW6dKOsUKFpr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "AA02_data = pd.read_csv(r\"equity-post-HCT-survival-predictions\\train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UfuOEJu_20x",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checking structure of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frwjwvoyLEjU",
    "outputId": "fe55ebba-10ae-4198-ac49-972bead63637"
   },
   "outputs": [],
   "source": [
    "# AA02_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFxQYHKZKmGJ",
    "outputId": "921a7bb1-9931-464a-a334-74e735191276"
   },
   "outputs": [],
   "source": [
    "# AA02_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pomKw8hsm4Nd",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3I5RVel8TUT",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "u3ead7MnL41i",
    "outputId": "1889c420-9f54-402d-ee74-208d705cc349"
   },
   "outputs": [],
   "source": [
    "# Sample 5001 of the data\n",
    "# AA02_sample_data_0 = AA02_data.sample(n=5001, random_state=55002)\n",
    "\n",
    "AA02_sample_data_0 = AA02_data.copy()\n",
    "\n",
    "# AA02_display the first few rows of the sample\n",
    "# AA02_sample_data_0.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "d1uDXbKRBmni"
   },
   "outputs": [],
   "source": [
    "def AA02_check_unique_values(dataframe):\n",
    "    \"\"\"\n",
    "    Calculate the number of unique values, total values,\n",
    "    and percentage of unique values for each column in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A summary DataFrame with unique value statistics.\n",
    "    \"\"\"\n",
    "    # Calculate unique values, total values, and percentage of unique values\n",
    "    unique_counts = dataframe.nunique()\n",
    "    total_counts = dataframe.count()\n",
    "    percentages = (unique_counts / total_counts) * 100\n",
    "\n",
    "    # Combine the results into a DataFrame for better AA02_display\n",
    "    summary_AA02_df = pd.DataFrame({\n",
    "        'Unique Values': unique_counts,\n",
    "        'Total Values': total_counts,\n",
    "        'Percentage (%)': percentages\n",
    "    })\n",
    "\n",
    "    return summary_AA02_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbzX_Hst9FgJ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Categorizing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lz47rFRxMeFg",
    "outputId": "b93e9714-9e21-4638-b58f-7483f67d06d8"
   },
   "outputs": [],
   "source": [
    "# AA02_sample_data_0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "iLENaFKhCCZY",
    "outputId": "c300e4f6-dd5e-4871-e1ff-41ad0ecbf488"
   },
   "outputs": [],
   "source": [
    "# Check whether a Variable is index or not\n",
    "# AA02_check_unique_values(AA02_sample_data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = r'equity-post-HCT-survival-predictions\\data_dictionary.csv'  # Update with your actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract all variables\n",
    "AA02_columns = data['variable'].tolist()\n",
    "\n",
    "# Display the results\n",
    "# print(\"All Columns:\", AA02_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "s0MATwLn-rrs",
    "outputId": "71f4a2f1-aea4-4be8-a66a-48f9d71758a0"
   },
   "outputs": [],
   "source": [
    "AA02_sample_data_1 = AA02_sample_data_0[AA02_columns]\n",
    "# AA02_sample_data_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "IlYKcegPMXq-",
    "outputId": "69b61b95-ad2b-4b14-ce0d-ec64731ccb35"
   },
   "outputs": [],
   "source": [
    "# Verify whether all variables are non index variables\n",
    "# AA02_check_unique_values(AA02_sample_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "FpivejDiEVvn"
   },
   "outputs": [],
   "source": [
    "data['type'] = data['type'].str.strip().str.lower()\n",
    "\n",
    "# Separate categorical and numerical columns\n",
    "AA02_categorical_columns = data[data['type'] == 'categorical']['variable'].tolist()\n",
    "AA02_non_categorical_columns = data[data['type'] == 'numerical']['variable'].tolist()\n",
    "# print(\"Categorical Columns:\", AA02_categorical_columns)\n",
    "# print(\"Numerical Columns:\", AA02_non_categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "CIka3FHcG6lU"
   },
   "outputs": [],
   "source": [
    "## Divde Categorical variable into two parts ordinal & nominal\n",
    "AA02_categorical_ordinal_columns = []\n",
    "AA02_categorical_nominal_columns = AA02_categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ti7Mdslz-4M5"
   },
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRs62a3D-6bl",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Checking Missing Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "0PRa13NhMpIr",
    "outputId": "a448a031-46a0-46a2-d80e-988b35e3cccc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate missing data information\n",
    "def AA02_missing_data_info(AA02_sample_data):\n",
    "    # Calculate missing count and percentage\n",
    "    AA02_missing_count = AA02_sample_data.isnull().sum()\n",
    "    AA02_missing_percentage = (AA02_missing_count / len(AA02_sample_data)) * 100\n",
    "\n",
    "    # Create a DataFrame with missing data information\n",
    "    AA02_missing_info = pd.DataFrame({\n",
    "        'AA02_Variable': AA02_sample_data.columns,\n",
    "        'AA02_Missing_Count': AA02_missing_count.values,\n",
    "        'AA02_Missing_Percentage': AA02_missing_percentage.values\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "    # Format the percentage column\n",
    "    AA02_missing_info['AA02_Missing_Percentage'] = AA02_missing_info['AA02_Missing_Percentage'].round(2).astype(str) + '%'\n",
    "\n",
    "    return AA02_missing_info\n",
    "\n",
    "# Call the function\n",
    "# AA02_missing_data_info(AA02_sample_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Omitted Due to Missing Values (> 50%):\n",
      "    Variable  Missing_Percentage              Omitted_From\n",
      "0    mrd_hct               57.63  AA02_categorical_columns\n",
      "1  tce_match               65.96  AA02_categorical_columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to omit variables with more than a threshold of missing values and log omitted variables\n",
    "def AA02_clean_data_with_logging(\n",
    "    AA02_sample_data,\n",
    "    AA02_categorical_columns,\n",
    "    AA02_non_categorical_columns,\n",
    "    AA02_columns,\n",
    "    missing_threshold=50\n",
    "):\n",
    "    # Calculate missing percentage for each variable\n",
    "    AA02_missing_percentage = (AA02_sample_data.isnull().sum() / len(AA02_sample_data)) * 100\n",
    "\n",
    "    # Identify variables to omit (missing percentage > threshold)\n",
    "    variables_to_omit = AA02_missing_percentage[AA02_missing_percentage > missing_threshold]\n",
    "\n",
    "    # Create a DataFrame for omitted variables\n",
    "    omitted_info = []\n",
    "    for variable, percentage in variables_to_omit.items():\n",
    "        if variable in AA02_categorical_columns:\n",
    "            source = \"AA02_categorical_columns\"\n",
    "        elif variable in AA02_non_categorical_columns:\n",
    "            source = \"AA02_non_categorical_columns\"\n",
    "        elif variable in AA02_columns:\n",
    "            source = \"AA02_columns\"\n",
    "        else:\n",
    "            source = \"Unknown\"\n",
    "\n",
    "        omitted_info.append({\n",
    "            \"Variable\": variable,\n",
    "            \"Missing_Percentage\": round(percentage, 2),\n",
    "            \"Omitted_From\": source\n",
    "        })\n",
    "\n",
    "    # Convert omitted info to DataFrame\n",
    "    AA02_omitted_df = pd.DataFrame(omitted_info)\n",
    "\n",
    "    # Identify variables to keep\n",
    "    variables_to_keep = AA02_missing_percentage[AA02_missing_percentage <= missing_threshold].index.tolist()\n",
    "\n",
    "    # Filter the dataset\n",
    "    AA02_sample_data_cleaned = AA02_sample_data[variables_to_keep]\n",
    "\n",
    "    # Update the lists (only keep variables that are not omitted)\n",
    "    AA02_columns[:] = [col for col in AA02_columns if col in variables_to_keep]\n",
    "    AA02_categorical_columns[:] = [col for col in AA02_categorical_columns if col in variables_to_keep]\n",
    "    AA02_non_categorical_columns[:] = [col for col in AA02_non_categorical_columns if col in variables_to_keep]\n",
    "\n",
    "    # Print the DataFrame of omitted variables\n",
    "    print(\"Variables Omitted Due to Missing Values (> {}%):\".format(missing_threshold))\n",
    "    print(AA02_omitted_df)\n",
    "\n",
    "    return AA02_sample_data_cleaned\n",
    "\n",
    "# Example usage\n",
    "# Assuming AA02_sample_data_1, AA02_categorical_columns, AA02_non_categorical_columns, and AA02_columns are defined\n",
    "AA02_sample_data_cleaned = AA02_clean_data_with_logging(\n",
    "    AA02_sample_data_1,\n",
    "    AA02_categorical_columns,\n",
    "    AA02_non_categorical_columns,\n",
    "    AA02_columns,\n",
    "    missing_threshold=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(AA02_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping variables from data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select variables from AA02_sample_data_1 that are present in AA02_columns\n",
    "AA02_sample_data_dropped_variable = AA02_sample_data_1[AA02_columns]\n",
    "\n",
    "# Display the resulting dataset\n",
    "# AA02_sample_data_dropped_variable.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkKZhWQY-Eff",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Categorical Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "-RZE8cm3p-RJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer # type: ignore\n",
    "\n",
    "AA02_sample_data_imputed = AA02_sample_data_dropped_variable.copy()\n",
    "\n",
    "# Initialize SimpleImputer with most_frequent strategy\n",
    "AA02_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Apply imputation\n",
    "AA02_sample_data_imputed[AA02_categorical_columns] = AA02_imputer.fit_transform(AA02_sample_data_imputed[AA02_categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJCx0uVJ-JHn"
   },
   "source": [
    "### Non Categorical Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqtOvgJmoFbq",
    "outputId": "260e3282-addb-4a1a-fb9d-9a4a9803c6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing 'hla_match_c_high' with median (significant difference between mean and median)\n",
      "Imputing 'hla_high_res_8' with median (significant difference between mean and median)\n",
      "Imputing 'hla_low_res_6' with median (significant difference between mean and median)\n",
      "Imputing 'hla_high_res_6' with median (significant difference between mean and median)\n",
      "Imputing 'hla_high_res_10' with median (significant difference between mean and median)\n",
      "Imputing 'hla_match_dqb1_high' with median (significant difference between mean and median)\n",
      "Imputing 'hla_nmdp_6' with median (significant difference between mean and median)\n",
      "Imputing 'hla_match_c_low' with median (significant difference between mean and median)\n",
      "Imputing 'hla_match_drb1_low' with median (significant difference between mean and median)\n",
      "Imputing 'hla_match_dqb1_low' with median (significant difference between mean and median)\n",
      "Imputing 'hla_match_a_high' with median (significant difference between mean and median)\n",
      "Imputing 'donor_age' with mean (no significant difference between mean and median)\n",
      "Imputing 'hla_match_b_low' with median (significant difference between mean and median)\n",
      "Imputing 'hla_match_a_low' with median (significant difference between mean and median)\n",
      "Imputing 'hla_match_b_high' with median (significant difference between mean and median)\n",
      "Imputing 'comorbidity_score' with median (significant difference between mean and median)\n",
      "Imputing 'karnofsky_score' with mean (no significant difference between mean and median)\n",
      "Imputing 'hla_low_res_8' with median (significant difference between mean and median)\n",
      "Imputing 'hla_match_drb1_high' with median (significant difference between mean and median)\n",
      "Imputing 'hla_low_res_10' with median (significant difference between mean and median)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer # type: ignore\n",
    "import numpy as np\n",
    "\n",
    "def AA02_impute_columns_with_mean_or_median(AA02_df, columns):\n",
    "    for col in columns:\n",
    "        # Ensure column is numeric\n",
    "        AA02_df[col] = pd.to_numeric(AA02_df[col], errors='coerce')\n",
    "\n",
    "        # Replace invalid values with NaN\n",
    "        AA02_df[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "        # Skip if column has no missing values\n",
    "        if AA02_df[col].isnull().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        # Calculate mean and median\n",
    "        AA02_col_mean = AA02_df[col].mean()\n",
    "        AA02_col_median = AA02_df[col].median()\n",
    "\n",
    "        # Choose strategy based on significant difference\n",
    "        if abs(AA02_col_mean - AA02_col_median) / max(abs(AA02_col_mean), abs(AA02_col_median)) > 0.1:  # Significant difference\n",
    "            print(f\"Imputing '{col}' with median (significant difference between mean and median)\")\n",
    "            AA02_imputer = SimpleImputer(strategy='median')\n",
    "        else:\n",
    "            print(f\"Imputing '{col}' with mean (no significant difference between mean and median)\")\n",
    "            AA02_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "        # Apply the AA02_imputer\n",
    "        AA02_df[[col]] = AA02_imputer.fit_transform(AA02_df[[col]])\n",
    "\n",
    "    return AA02_df\n",
    "\n",
    "AA02_sample_data_imputed = AA02_impute_columns_with_mean_or_median(AA02_sample_data_imputed, AA02_non_categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMHMflEy-_Qm",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Verify Missing Percetage = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "g9D3leRZqt0y",
    "outputId": "59581284-9be4-4e1a-f67d-7e8579b833fb"
   },
   "outputs": [],
   "source": [
    "# AA02_missing_data_info(AA02_sample_data_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODojRQ9f_La3"
   },
   "source": [
    "## Numerical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0k7gUB0_NWr"
   },
   "source": [
    "### Ordinal/Nominal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "7UV-1hFXKyWM",
    "outputId": "11f0d0b3-c732-49a5-a159-3c1287d14cd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Encoded Categorical Variables:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder # type: ignore\n",
    "\n",
    "# Define order for ordinal columns\n",
    "AA02_ordinal_categories = [\n",
    "    # ['Import', 'Export'],  # Order for 'Import_Export'\n",
    "    # ['B', 'A']             # Order for 'Grades' (A is superior to B) A will be written as 1 and b will be written as 0\n",
    "]\n",
    "# Initialize OrdinalEncoder for ordinal columns with specified order\n",
    "ordinal_encoder_ordinal = OrdinalEncoder(categories=AA02_ordinal_categories)\n",
    "\n",
    "# Initialize OrdinalEncoder for nominal columns (order does not matter)\n",
    "ordinal_encoder_nominal = OrdinalEncoder()\n",
    "\n",
    "# Make a copy of the DataFrame\n",
    "AA02_sample_data_ordinally_encoded = AA02_sample_data_imputed.copy()\n",
    "\n",
    "# Encode ordinal columns\n",
    "AA02_sample_data_ordinally_encoded[AA02_categorical_ordinal_columns] = ordinal_encoder_ordinal.fit_transform(\n",
    "    AA02_sample_data_ordinally_encoded[AA02_categorical_ordinal_columns].astype(str)\n",
    ")\n",
    "\n",
    "# Encode nominal columns\n",
    "AA02_sample_data_ordinally_encoded[AA02_categorical_nominal_columns] = ordinal_encoder_nominal.fit_transform(\n",
    "    AA02_sample_data_ordinally_encoded[AA02_categorical_nominal_columns].astype(str)\n",
    ")\n",
    "\n",
    "# AA02_display the encoded DataFrame\n",
    "print(\"DataFrame with Encoded Categorical Variables:\")\n",
    "# AA02_sample_data_ordinally_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOFADEPn_X0Q"
   },
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "Cw2IPoP5QnxR",
    "outputId": "cdf334bc-2526-4b6d-d668-fcbb138ffed1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import PowerTransformer # type: ignore\n",
    "import pandas as pd\n",
    "\n",
    "# Function to handle transformations based on distribution characteristics\n",
    "def apply_transformations(AA02_sample_data, columns):\n",
    "    # Initialize a list to store transformation logs\n",
    "    AA02_transformation_logs = []\n",
    "\n",
    "    for column in columns:\n",
    "        # Compute AA02_skewness and AA02_kurtosis\n",
    "        AA02_skewness = AA02_sample_data[column].skew()\n",
    "        AA02_kurtosis = AA02_sample_data[column].kurt()\n",
    "        AA02_action = \"None\"  # Default AA02_action\n",
    "\n",
    "        # Handle Right Skew (Positive Skew)\n",
    "        if AA02_skewness > 1:\n",
    "            AA02_action = \"Log Transformation\"\n",
    "            AA02_sample_data[column] = np.log1p(AA02_sample_data[column])\n",
    "\n",
    "        # Handle Left Skew (Negative Skew)\n",
    "        elif AA02_skewness < -1:\n",
    "            AA02_action = \"Reflect and Log Transformation\"\n",
    "            AA02_sample_data[column] = np.log1p(AA02_sample_data[column].max() - AA02_sample_data[column])\n",
    "\n",
    "        # Handle High Kurtosis (Heavy Tails)\n",
    "        if AA02_kurtosis > 3:\n",
    "            try:\n",
    "                AA02_action = \"Box-Cox Transformation\"\n",
    "                AA02_sample_data[column], _ = boxcox(AA02_sample_data[column].clip(lower=1))\n",
    "            except ValueError:\n",
    "                AA02_action = \"Box-Cox Failed, Applied Yeo-Johnson\"\n",
    "                transformer = PowerTransformer(method='yeo-johnson')\n",
    "                AA02_sample_data[column] = transformer.fit_transform(AA02_sample_data[[column]])\n",
    "\n",
    "        # Handle Low Kurtosis (Light Tails)\n",
    "        elif AA02_kurtosis < 3 and AA02_action == \"None\":\n",
    "            AA02_action = \"Yeo-Johnson Transformation\"\n",
    "            transformer = PowerTransformer(method='yeo-johnson')\n",
    "            AA02_sample_data[column] = transformer.fit_transform(AA02_sample_data[[column]])\n",
    "\n",
    "        # Append the log entry\n",
    "        AA02_transformation_logs.append({\n",
    "            'Column Name': column,\n",
    "            'Skewness': AA02_skewness,\n",
    "            'Kurtosis': AA02_kurtosis,\n",
    "            'Action Taken': AA02_action\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame for transformation logs\n",
    "    transformation_log_AA02_df = pd.DataFrame(AA02_transformation_logs)\n",
    "    return AA02_sample_data, transformation_log_AA02_df\n",
    "\n",
    "# Example usage with AA02_sample_data_encoded\n",
    "AA02_sample_data_encoded = AA02_sample_data_ordinally_encoded.copy()\n",
    "AA02_sample_data_encoded, AA02_transformation_logs = apply_transformations(AA02_sample_data_encoded, AA02_non_categorical_columns)\n",
    "\n",
    "# AA02_display the transformation log DataFrame\n",
    "# print(\"Transformation Log:\")\n",
    "# AA02_transformation_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Iw0Z1A-kWvcY",
    "outputId": "a5644a9a-1fe5-4cc4-ac23-674592f04312"
   },
   "outputs": [],
   "source": [
    "# Code for AA02_displaying transformed datset\n",
    "# AA02_sample_data_encoded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-8ALf89nQZZ"
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaFy3CxZBzTp"
   },
   "source": [
    "## Dependent/Independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQJctu_ICD-7"
   },
   "source": [
    "### Function to define Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "oR57j0RfYpbC"
   },
   "outputs": [],
   "source": [
    "def prepare_data(AA02_y_vars, AA02_cat_vars, AA02_non_cat_vars):\n",
    "    \"\"\"\n",
    "    Prepares the data by calculating the feature set (AA02_x) while excluding dependent variables.\n",
    "\n",
    "    Args:\n",
    "    - AA02_y_vars: A list of dependent variable names (can handle multiple dependent variables).\n",
    "    - AA02_cat_vars: A list of categorical variable names.\n",
    "    - AA02_non_cat_vars: A list of non-categorical variable names.\n",
    "\n",
    "    Returns:\n",
    "    - AA02_y_vars: A list of dependent variable names.\n",
    "    - AA02_x: A list of feature variable names, excluding dependent variables.\n",
    "    \"\"\"\n",
    "    # Combine categorical and non-categorical variable lists\n",
    "    AA02_all_vars = AA02_cat_vars + AA02_non_cat_vars\n",
    "\n",
    "    # Ensure `AA02_y_vars` is a list for consistency\n",
    "    if isinstance(AA02_y_vars, str):\n",
    "        AA02_y_vars = [AA02_y_vars]\n",
    "\n",
    "    # Calculate the feature set (x) as the difference between AA02_all_vars and y_vars\n",
    "    AA02_x = [AA02_var for AA02_var in AA02_all_vars if AA02_var not in AA02_y_vars]\n",
    "\n",
    "    return AA02_y_vars, AA02_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHGA4QiaCI2p",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Defining Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIMrNabZyyLf",
    "outputId": "06033a03-09e2-4cd0-d88f-496abd77b6bd"
   },
   "outputs": [],
   "source": [
    "AA02_y = ['efs', 'efs_time']  # Target variable defined manually\n",
    "\n",
    "AA02_y_columns, AA02_x_columns = prepare_data(AA02_y, AA02_categorical_columns, AA02_non_categorical_columns)\n",
    "\n",
    "# print(\"Target (y):\", AA02_y_columns)\n",
    "# print(\"Feature Set (x):\", AA02_x_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jp2JPI4LCNOB"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "AA02_sample_data_5 = AA02_sample_data_encoded.copy()\n",
    "\n",
    "# Extract the target columns (multi-output targets)\n",
    "AA02_y_data = AA02_sample_data_5[AA02_y_columns]  # AA02_y_columns should be a list like ['efs', 'efs_time']\n",
    "\n",
    "# Extract the features (as DataFrame)\n",
    "AA02_x_data = AA02_sample_data_5[AA02_x_columns]  # AA02_x_columns is the list of feature column names\n",
    "\n",
    "# Perform the train-test split\n",
    "AA02_x_train, AA02_x_test, AA02_y_train, AA02_y_test = train_test_split(\n",
    "    AA02_x_data, AA02_y_data, test_size=None, random_state=55002, stratify=AA02_y_data['efs']  # Stratify by 'efs'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "# Check the correlation matrix\n",
    "correlation_matrix = AA02_x_train.corr()\n",
    "# print(\"Correlation Matrix:\\n\", correlation_matrix)\n",
    "\n",
    "# Perform factor analysis\n",
    "fa = FactorAnalyzer(n_factors=5, rotation=\"varimax\")  # Adjust 'n_factors' as needed\n",
    "fa.fit(AA02_x_train)\n",
    "\n",
    "# Get eigenvalues to decide the number of factors to retain\n",
    "eigenvalues, _ = fa.get_eigenvalues()\n",
    "# print(\"Eigenvalues:\\n\", eigenvalues)\n",
    "\n",
    "# Plot eigenvalues to visualize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(eigenvalues) + 1), eigenvalues, marker='o')\n",
    "plt.title(\"Scree Plot\")\n",
    "plt.xlabel(\"Factor\")\n",
    "plt.ylabel(\"Eigenvalue\")\n",
    "plt.axhline(1, color='red', linestyle='--')  # Retain factors with eigenvalue > 1\n",
    "plt.show()\n",
    "\n",
    "# Factor loadings\n",
    "factor_loadings = pd.DataFrame(fa.loadings_, index=AA02_x_train.columns)\n",
    "# print(\"Factor Loadings:\\n\", factor_loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select important variables (e.g., variables with loadings > 0.5)\n",
    "important_variables = factor_loadings[(factor_loadings.abs() > 0.5).any(axis=1)]\n",
    "# print(\"Important Variables:\\n\", important_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of important variables including 'efs'\n",
    "important_variables_list = list(important_variables.index)  # Extract variable names from important_variables\n",
    "\n",
    "# Ensure 'efs' is included in the list\n",
    "# if 'efs' not in important_variables_list:\n",
    "    # important_variables_list.append('efs')  # Add 'efs' explicitly to the list\n",
    "\n",
    "# Subset train and test datasets\n",
    "AA02_x_train = AA02_x_train[important_variables_list]\n",
    "AA02_x_test = AA02_x_test[important_variables_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms1QBRlXCxQh",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Train test split verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Compute unique value counts for AA02_x_train and AA02_x_test\n",
    "AA02_unique_values_AA02_x_train = AA02_x_train.nunique()\n",
    "AA02_unique_values_AA02_x_test = AA02_x_test.nunique()\n",
    "\n",
    "# Safely compute unique value counts for dependent variables in AA02_y_train and AA02_y_test\n",
    "AA02_unique_values_AA02_y_train = {}\n",
    "AA02_unique_values_AA02_y_test = {}\n",
    "\n",
    "for y in AA02_y_columns:\n",
    "    if y in AA02_y_train.columns:\n",
    "        AA02_unique_values_AA02_y_train[y] = AA02_y_train[y].nunique()\n",
    "    else:\n",
    "        print(f\"Warning: '{y}' not found in AA02_y_train\")\n",
    "    \n",
    "    if y in AA02_y_test.columns:\n",
    "        AA02_unique_values_AA02_y_test[y] = AA02_y_test[y].nunique()\n",
    "    else:\n",
    "        print(f\"Warning: '{y}' not found in AA02_y_test\")\n",
    "\n",
    "# Convert to pandas Series\n",
    "AA02_unique_values_AA02_y_train = pd.Series(AA02_unique_values_AA02_y_train)\n",
    "AA02_unique_values_AA02_y_test = pd.Series(AA02_unique_values_AA02_y_test)\n",
    "\n",
    "# Combine the results into a single DataFrame\n",
    "AA02_unique_values_AA02_df = pd.DataFrame({\n",
    "    'AA02_x_train': AA02_unique_values_AA02_x_train,\n",
    "    'AA02_x_test': AA02_unique_values_AA02_x_test,\n",
    "    'AA02_y_train': AA02_unique_values_AA02_y_train,\n",
    "    'AA02_y_test': AA02_unique_values_AA02_y_test\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "# AA02_unique_values_AA02_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the results DataFrame\n",
    "results_list = []\n",
    "\n",
    "# Ensure important variables list is at least 100% of total columns\n",
    "min_important_vars = max(int(0.97 * len(important_variables_list)), 1)\n",
    "\n",
    "# Generate all combinations of variables meeting the 100% condition\n",
    "for r in range(min_important_vars, len(important_variables_list) + 1):\n",
    "    for subset in combinations(important_variables_list, r):\n",
    "        # Subset the train and test data\n",
    "        AA02_x_train_subset = AA02_x_train[list(subset)]\n",
    "        AA02_x_test_subset = AA02_x_test[list(subset)]\n",
    "\n",
    "        # Define the model\n",
    "        input_layer = Input(shape=(AA02_x_train_subset.shape[1],), name=\"input_layer\")\n",
    "        shared_layer = Dense(128, activation=\"relu\")(input_layer)\n",
    "        shared_layer = Dropout(0.3)(shared_layer)\n",
    "        shared_layer = Dense(64, activation=\"relu\")(shared_layer)\n",
    "        efs_time_output = Dense(1, activation=\"linear\", name=\"efs_time_output\")(shared_layer)\n",
    "\n",
    "        model = Model(inputs=input_layer, outputs=efs_time_output)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            AA02_x_train_subset,\n",
    "            AA02_y_train[\"efs_time\"],\n",
    "            validation_data=(AA02_x_test_subset, AA02_y_test[\"efs_time\"]),\n",
    "            epochs=10,\n",
    "            batch_size=64,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict and evaluate\n",
    "        efs_time_predictions = model.predict(AA02_x_test_subset).ravel()\n",
    "        event_indicator = AA02_y_test[\"efs\"].values.astype(bool)\n",
    "        event_time = AA02_y_test[\"efs_time\"].values\n",
    "\n",
    "        efs_time_cindex = concordance_index_censored(\n",
    "            event_indicator,  # Event indicator\n",
    "            event_time,       # Observed survival times\n",
    "            -efs_time_predictions  # Predicted risk scores\n",
    "        )\n",
    "        if isinstance(efs_time_cindex, tuple):\n",
    "            efs_time_cindex = efs_time_cindex[0]\n",
    "\n",
    "        efs_time_r2 = r2_score(AA02_y_test[\"efs_time\"], efs_time_predictions)\n",
    "\n",
    "        # Store results in a dictionary\n",
    "        result = {\n",
    "            \"C-index\": efs_time_cindex,\n",
    "            \"R\": efs_time_r2\n",
    "        }\n",
    "\n",
    "        # Add variable presence\n",
    "        for var in important_variables_list:\n",
    "            result[var] = 1 if var in subset else 0\n",
    "\n",
    "        results_list.append(result)\n",
    "\n",
    "# Convert results list to DataFrame\n",
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C-index</th>\n",
       "      <th>R</th>\n",
       "      <th>dri_score</th>\n",
       "      <th>graft_type</th>\n",
       "      <th>tce_imm_match</th>\n",
       "      <th>prod_type</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <th>...</th>\n",
       "      <th>hla_match_dqb1_low</th>\n",
       "      <th>hla_match_a_high</th>\n",
       "      <th>hla_match_b_low</th>\n",
       "      <th>age_at_hct</th>\n",
       "      <th>hla_match_a_low</th>\n",
       "      <th>hla_match_b_high</th>\n",
       "      <th>comorbidity_score</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.621059</td>\n",
       "      <td>0.082448</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.626136</td>\n",
       "      <td>0.079978</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.619670</td>\n",
       "      <td>0.078845</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.612864</td>\n",
       "      <td>0.066270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.622464</td>\n",
       "      <td>0.073556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.619155</td>\n",
       "      <td>0.064728</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.623180</td>\n",
       "      <td>0.078843</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.628389</td>\n",
       "      <td>0.088159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.625458</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.621243</td>\n",
       "      <td>0.074238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.624628</td>\n",
       "      <td>0.083968</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.621626</td>\n",
       "      <td>0.074272</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.625119</td>\n",
       "      <td>0.073920</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.618274</td>\n",
       "      <td>0.075952</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.623472</td>\n",
       "      <td>0.035492</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.623906</td>\n",
       "      <td>0.068174</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.620753</td>\n",
       "      <td>0.073828</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.619040</td>\n",
       "      <td>0.040162</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.622948</td>\n",
       "      <td>0.082523</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.617477</td>\n",
       "      <td>0.075029</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.622108</td>\n",
       "      <td>0.082944</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.622726</td>\n",
       "      <td>0.076036</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.622905</td>\n",
       "      <td>0.080036</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.617505</td>\n",
       "      <td>0.051187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.605985</td>\n",
       "      <td>0.059073</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.620800</td>\n",
       "      <td>0.079711</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     C-index        R  dri_score  graft_type  tce_imm_match  prod_type  \\\n",
       "0   0.621059  0.082448          1           1              1          1   \n",
       "1   0.626136  0.079978          1           1              1          1   \n",
       "2   0.619670  0.078845          1           1              1          1   \n",
       "3   0.612864  0.066270          1           1              1          1   \n",
       "4   0.622464  0.073556          1           1              1          1   \n",
       "5   0.619155  0.064728          1           1              1          1   \n",
       "6   0.623180  0.078843          1           1              1          1   \n",
       "7   0.628389  0.088159          1           1              1          1   \n",
       "8   0.625458  0.086957          1           1              1          1   \n",
       "9   0.621243  0.074238          1           1              1          1   \n",
       "10  0.624628  0.083968          1           1              1          1   \n",
       "11  0.621626  0.074272          1           1              1          1   \n",
       "12  0.625119  0.073920          1           1              1          1   \n",
       "13  0.618274  0.075952          1           1              1          1   \n",
       "14  0.623472  0.035492          1           1              1          1   \n",
       "15  0.623906  0.068174          1           1              1          1   \n",
       "16  0.620753  0.073828          1           1              1          1   \n",
       "17  0.619040  0.040162          1           1              1          1   \n",
       "18  0.622948  0.082523          1           1              1          1   \n",
       "19  0.617477  0.075029          1           1              1          1   \n",
       "20  0.622108  0.082944          1           1              1          1   \n",
       "21  0.622726  0.076036          1           1              1          0   \n",
       "22  0.622905  0.080036          1           1              0          1   \n",
       "23  0.617505  0.051187          1           0              1          1   \n",
       "24  0.605985  0.059073          0           1              1          1   \n",
       "25  0.620800  0.079711          1           1              1          1   \n",
       "\n",
       "    tce_div_match  donor_related  hla_match_c_high  hla_high_res_8  ...  \\\n",
       "0               1              1                 1               1  ...   \n",
       "1               1              1                 1               1  ...   \n",
       "2               1              1                 1               1  ...   \n",
       "3               1              1                 1               1  ...   \n",
       "4               1              1                 1               1  ...   \n",
       "5               1              1                 1               1  ...   \n",
       "6               1              1                 1               1  ...   \n",
       "7               1              1                 1               1  ...   \n",
       "8               1              1                 1               1  ...   \n",
       "9               1              1                 1               1  ...   \n",
       "10              1              1                 1               1  ...   \n",
       "11              1              1                 1               1  ...   \n",
       "12              1              1                 1               1  ...   \n",
       "13              1              1                 1               1  ...   \n",
       "14              1              1                 1               1  ...   \n",
       "15              1              1                 1               1  ...   \n",
       "16              1              1                 1               1  ...   \n",
       "17              1              1                 1               0  ...   \n",
       "18              1              1                 0               1  ...   \n",
       "19              1              0                 1               1  ...   \n",
       "20              0              1                 1               1  ...   \n",
       "21              1              1                 1               1  ...   \n",
       "22              1              1                 1               1  ...   \n",
       "23              1              1                 1               1  ...   \n",
       "24              1              1                 1               1  ...   \n",
       "25              1              1                 1               1  ...   \n",
       "\n",
       "    hla_match_dqb1_low  hla_match_a_high  hla_match_b_low  age_at_hct  \\\n",
       "0                    1                 1                1           1   \n",
       "1                    1                 1                1           1   \n",
       "2                    1                 1                1           1   \n",
       "3                    1                 1                1           1   \n",
       "4                    1                 1                1           1   \n",
       "5                    1                 1                1           1   \n",
       "6                    1                 1                1           0   \n",
       "7                    1                 1                0           1   \n",
       "8                    1                 0                1           1   \n",
       "9                    0                 1                1           1   \n",
       "10                   1                 1                1           1   \n",
       "11                   1                 1                1           1   \n",
       "12                   1                 1                1           1   \n",
       "13                   1                 1                1           1   \n",
       "14                   1                 1                1           1   \n",
       "15                   1                 1                1           1   \n",
       "16                   1                 1                1           1   \n",
       "17                   1                 1                1           1   \n",
       "18                   1                 1                1           1   \n",
       "19                   1                 1                1           1   \n",
       "20                   1                 1                1           1   \n",
       "21                   1                 1                1           1   \n",
       "22                   1                 1                1           1   \n",
       "23                   1                 1                1           1   \n",
       "24                   1                 1                1           1   \n",
       "25                   1                 1                1           1   \n",
       "\n",
       "    hla_match_a_low  hla_match_b_high  comorbidity_score  hla_low_res_8  \\\n",
       "0                 1                 1                  1              1   \n",
       "1                 1                 1                  1              1   \n",
       "2                 1                 1                  1              0   \n",
       "3                 1                 1                  0              1   \n",
       "4                 1                 0                  1              1   \n",
       "5                 0                 1                  1              1   \n",
       "6                 1                 1                  1              1   \n",
       "7                 1                 1                  1              1   \n",
       "8                 1                 1                  1              1   \n",
       "9                 1                 1                  1              1   \n",
       "10                1                 1                  1              1   \n",
       "11                1                 1                  1              1   \n",
       "12                1                 1                  1              1   \n",
       "13                1                 1                  1              1   \n",
       "14                1                 1                  1              1   \n",
       "15                1                 1                  1              1   \n",
       "16                1                 1                  1              1   \n",
       "17                1                 1                  1              1   \n",
       "18                1                 1                  1              1   \n",
       "19                1                 1                  1              1   \n",
       "20                1                 1                  1              1   \n",
       "21                1                 1                  1              1   \n",
       "22                1                 1                  1              1   \n",
       "23                1                 1                  1              1   \n",
       "24                1                 1                  1              1   \n",
       "25                1                 1                  1              1   \n",
       "\n",
       "    hla_match_drb1_high  hla_low_res_10  \n",
       "0                     1               0  \n",
       "1                     0               1  \n",
       "2                     1               1  \n",
       "3                     1               1  \n",
       "4                     1               1  \n",
       "5                     1               1  \n",
       "6                     1               1  \n",
       "7                     1               1  \n",
       "8                     1               1  \n",
       "9                     1               1  \n",
       "10                    1               1  \n",
       "11                    1               1  \n",
       "12                    1               1  \n",
       "13                    1               1  \n",
       "14                    1               1  \n",
       "15                    1               1  \n",
       "16                    1               1  \n",
       "17                    1               1  \n",
       "18                    1               1  \n",
       "19                    1               1  \n",
       "20                    1               1  \n",
       "21                    1               1  \n",
       "22                    1               1  \n",
       "23                    1               1  \n",
       "24                    1               1  \n",
       "25                    1               1  \n",
       "\n",
       "[26 rows x 27 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = r'equity-post-HCT-survival-predictions/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>dri_score</th>\n",
       "      <th>psych_disturb</th>\n",
       "      <th>cyto_score</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <th>tbi_status</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <th>...</th>\n",
       "      <th>karnofsky_score</th>\n",
       "      <th>hepatic_mild</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>melphalan_dose</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>cardiac</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>pulm_moderate</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28800</td>\n",
       "      <td>N/A - non-malignant indication</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrelated</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28801</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>TBI +- Other, &gt;cGy</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28802</td>\n",
       "      <td>N/A - non-malignant indication</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                       dri_score psych_disturb    cyto_score diabetes  \\\n",
       "0  28800  N/A - non-malignant indication            No           NaN       No   \n",
       "1  28801                    Intermediate            No  Intermediate       No   \n",
       "2  28802  N/A - non-malignant indication            No           NaN       No   \n",
       "\n",
       "   hla_match_c_high  hla_high_res_8          tbi_status arrhythmia  \\\n",
       "0               NaN             NaN              No TBI         No   \n",
       "1               2.0             8.0  TBI +- Other, >cGy         No   \n",
       "2               2.0             8.0              No TBI         No   \n",
       "\n",
       "   hla_low_res_6  ... karnofsky_score hepatic_mild          tce_div_match  \\\n",
       "0            6.0  ...            90.0           No                    NaN   \n",
       "1            6.0  ...            90.0           No  Permissive mismatched   \n",
       "2            6.0  ...            90.0           No  Permissive mismatched   \n",
       "\n",
       "  donor_related      melphalan_dose  hla_low_res_8 cardiac  \\\n",
       "0     Unrelated  N/A, Mel not given            8.0      No   \n",
       "1       Related  N/A, Mel not given            8.0      No   \n",
       "2       Related  N/A, Mel not given            8.0      No   \n",
       "\n",
       "   hla_match_drb1_high  pulm_moderate hla_low_res_10  \n",
       "0                  2.0             No           10.0  \n",
       "1                  2.0            Yes           10.0  \n",
       "2                  2.0             No           10.0  \n",
       "\n",
       "[3 rows x 58 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe = pd.read_csv(test_file_path)\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imputaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate missing data information\n",
    "def AA02_missing_data_info(AA02_sample_data):\n",
    "    # Calculate missing count and percentage\n",
    "    AA02_missing_count = AA02_sample_data.isnull().sum()\n",
    "    AA02_missing_percentage = (AA02_missing_count / len(AA02_sample_data)) * 100\n",
    "\n",
    "    # Create a DataFrame with missing data information\n",
    "    AA02_missing_info = pd.DataFrame({\n",
    "        'AA02_Variable': AA02_sample_data.columns,\n",
    "        'AA02_Missing_Count': AA02_missing_count.values,\n",
    "        'AA02_Missing_Percentage': AA02_missing_percentage.values\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "    # Format the percentage column\n",
    "    AA02_missing_info['AA02_Missing_Percentage'] = AA02_missing_info['AA02_Missing_Percentage'].round(2).astype(str) + '%'\n",
    "\n",
    "    return AA02_missing_info\n",
    "\n",
    "# Call the function\n",
    "# AA02_missing_data_info(test_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical imputaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer # type: ignore\n",
    "\n",
    "test_dataframe_imputed = test_dataframe.copy()\n",
    "\n",
    "# Initialize SimpleImputer with most_frequent strategy\n",
    "AA02_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "if 'efs' in AA02_categorical_columns:\n",
    "    AA02_categorical_columns.remove('efs')\n",
    "\n",
    "# Apply imputation\n",
    "test_dataframe_imputed[AA02_categorical_columns] = AA02_imputer.fit_transform(test_dataframe_imputed[AA02_categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Categorical Imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing 'hla_match_c_high' with mean (no significant difference between mean and median)\n",
      "Imputing 'hla_high_res_8' with mean (no significant difference between mean and median)\n",
      "Imputing 'hla_high_res_10' with mean (no significant difference between mean and median)\n",
      "Imputing 'donor_age' with mean (no significant difference between mean and median)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer # type: ignore\n",
    "import numpy as np\n",
    "\n",
    "def AA02_impute_columns_with_mean_or_median(AA02_df, columns):\n",
    "    for col in columns:\n",
    "        # Ensure column is numeric\n",
    "        AA02_df[col] = pd.to_numeric(AA02_df[col], errors='coerce')\n",
    "\n",
    "        # Replace invalid values with NaN\n",
    "        AA02_df[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "        # Skip if column has no missing values\n",
    "        if AA02_df[col].isnull().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        # Calculate mean and median\n",
    "        AA02_col_mean = AA02_df[col].mean()\n",
    "        AA02_col_median = AA02_df[col].median()\n",
    "\n",
    "        # Choose strategy based on significant difference\n",
    "        if abs(AA02_col_mean - AA02_col_median) / max(abs(AA02_col_mean), abs(AA02_col_median)) > 0.1:  # Significant difference\n",
    "            print(f\"Imputing '{col}' with median (significant difference between mean and median)\")\n",
    "            AA02_imputer = SimpleImputer(strategy='median')\n",
    "        else:\n",
    "            print(f\"Imputing '{col}' with mean (no significant difference between mean and median)\")\n",
    "            AA02_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "        # Apply the AA02_imputer\n",
    "        AA02_df[[col]] = AA02_imputer.fit_transform(AA02_df[[col]])\n",
    "\n",
    "    return AA02_df\n",
    "\n",
    "if 'efs_time' in AA02_non_categorical_columns:\n",
    "    AA02_non_categorical_columns.remove('efs_time')\n",
    "\n",
    "\n",
    "test_dataframe_imputed = AA02_impute_columns_with_mean_or_median(test_dataframe_imputed, AA02_non_categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Encoded Categorical Variables:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>dri_score</th>\n",
       "      <th>psych_disturb</th>\n",
       "      <th>cyto_score</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <th>tbi_status</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <th>...</th>\n",
       "      <th>karnofsky_score</th>\n",
       "      <th>hepatic_mild</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>melphalan_dose</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>cardiac</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>pulm_moderate</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  dri_score  psych_disturb  cyto_score  diabetes  hla_match_c_high  \\\n",
       "0  28800        1.0            0.0         0.0       0.0               2.0   \n",
       "1  28801        0.0            0.0         0.0       0.0               2.0   \n",
       "2  28802        1.0            0.0         0.0       0.0               2.0   \n",
       "\n",
       "   hla_high_res_8  tbi_status  arrhythmia  hla_low_res_6  ...  \\\n",
       "0             8.0         0.0         0.0            6.0  ...   \n",
       "1             8.0         1.0         0.0            6.0  ...   \n",
       "2             8.0         0.0         0.0            6.0  ...   \n",
       "\n",
       "   karnofsky_score  hepatic_mild  tce_div_match  donor_related  \\\n",
       "0             90.0           0.0            0.0            1.0   \n",
       "1             90.0           0.0            0.0            0.0   \n",
       "2             90.0           0.0            0.0            0.0   \n",
       "\n",
       "   melphalan_dose  hla_low_res_8  cardiac  hla_match_drb1_high  pulm_moderate  \\\n",
       "0             0.0            8.0      0.0                  2.0            0.0   \n",
       "1             0.0            8.0      0.0                  2.0            1.0   \n",
       "2             0.0            8.0      0.0                  2.0            0.0   \n",
       "\n",
       "   hla_low_res_10  \n",
       "0            10.0  \n",
       "1            10.0  \n",
       "2            10.0  \n",
       "\n",
       "[3 rows x 58 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder # type: ignore\n",
    "\n",
    "# Define order for ordinal columns\n",
    "AA02_ordinal_categories = [\n",
    "    # ['Import', 'Export'],  # Order for 'Import_Export'\n",
    "    # ['B', 'A']             # Order for 'Grades' (A is superior to B) A will be written as 1 and b will be written as 0\n",
    "]\n",
    "# Initialize OrdinalEncoder for ordinal columns with specified order\n",
    "ordinal_encoder_ordinal = OrdinalEncoder(categories=AA02_ordinal_categories)\n",
    "\n",
    "# Initialize OrdinalEncoder for nominal columns (order does not matter)\n",
    "ordinal_encoder_nominal = OrdinalEncoder()\n",
    "\n",
    "# Make a copy of the DataFrame\n",
    "test_dataframe_imputed_ordinally_encoded = test_dataframe_imputed.copy()\n",
    "\n",
    "# Encode ordinal columns\n",
    "test_dataframe_imputed_ordinally_encoded[AA02_categorical_ordinal_columns] = ordinal_encoder_ordinal.fit_transform(\n",
    "    test_dataframe_imputed_ordinally_encoded[AA02_categorical_ordinal_columns].astype(str)\n",
    ")\n",
    "\n",
    "# Encode nominal columns\n",
    "test_dataframe_imputed_ordinally_encoded[AA02_categorical_nominal_columns] = ordinal_encoder_nominal.fit_transform(\n",
    "    test_dataframe_imputed_ordinally_encoded[AA02_categorical_nominal_columns].astype(str)\n",
    ")\n",
    "\n",
    "# AA02_display the encoded DataFrame\n",
    "print(\"DataFrame with Encoded Categorical Variables:\")\n",
    "test_dataframe_imputed_ordinally_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>dri_score</th>\n",
       "      <th>psych_disturb</th>\n",
       "      <th>cyto_score</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <th>tbi_status</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <th>...</th>\n",
       "      <th>karnofsky_score</th>\n",
       "      <th>hepatic_mild</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>melphalan_dose</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>cardiac</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>pulm_moderate</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  dri_score  psych_disturb  cyto_score  diabetes  hla_match_c_high  \\\n",
       "0  28800        1.0            0.0         0.0       0.0               2.0   \n",
       "1  28801        0.0            0.0         0.0       0.0               2.0   \n",
       "2  28802        1.0            0.0         0.0       0.0               2.0   \n",
       "\n",
       "   hla_high_res_8  tbi_status  arrhythmia  hla_low_res_6  ...  \\\n",
       "0             8.0         0.0         0.0            6.0  ...   \n",
       "1             8.0         1.0         0.0            6.0  ...   \n",
       "2             8.0         0.0         0.0            6.0  ...   \n",
       "\n",
       "   karnofsky_score  hepatic_mild  tce_div_match  donor_related  \\\n",
       "0             90.0           0.0            0.0            1.0   \n",
       "1             90.0           0.0            0.0            0.0   \n",
       "2             90.0           0.0            0.0            0.0   \n",
       "\n",
       "   melphalan_dose  hla_low_res_8  cardiac  hla_match_drb1_high  pulm_moderate  \\\n",
       "0             0.0            8.0      0.0                  2.0            0.0   \n",
       "1             0.0            8.0      0.0                  2.0            1.0   \n",
       "2             0.0            8.0      0.0                  2.0            0.0   \n",
       "\n",
       "   hla_low_res_10  \n",
       "0            10.0  \n",
       "1            10.0  \n",
       "2            10.0  \n",
       "\n",
       "[3 rows x 58 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe_transformed, log = apply_transformations(test_dataframe_imputed_ordinally_encoded,AA02_non_categorical_columns) \n",
    "test_dataframe_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted_efs_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28800</td>\n",
       "      <td>0.968647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28801</td>\n",
       "      <td>0.835898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28802</td>\n",
       "      <td>1.082357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Predicted_efs_time\n",
       "0  28800            0.968647\n",
       "1  28801            0.835898\n",
       "2  28802            1.082357"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the dataset contains only the features the model was trained on\n",
    "AA02_x_test_subset = test_dataframe_transformed[AA02_x_train.columns.tolist()]\n",
    "\n",
    "# Make predictions\n",
    "efs_time_predictions = model.predict(AA02_x_test_subset)\n",
    "\n",
    "# Convert predictions to a suitable format (flatten the array)\n",
    "efs_time_predictions = efs_time_predictions.ravel()\n",
    "\n",
    "# Add predictions to the dataset for reference\n",
    "test_dataframe_transformed['Predicted_efs_time'] = efs_time_predictions\n",
    "\n",
    "# Create a DataFrame for ID and predictions\n",
    "predictions_output = test_dataframe_transformed[['ID', 'Predicted_efs_time']]\n",
    "\n",
    "# Display the DataFrame with ID and predictions\n",
    "predictions_output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Submission.csv still need to be made\n",
    "enchance the c-index\n",
    "use multi threading for enhanced c-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Closed"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Ov_P-pFvmxDc",
    "9UfuOEJu_20x",
    "pomKw8hsm4Nd",
    "-c0vzp-EnMXR",
    "zLQrAG0mBeZ2",
    "Lcd9-pVWBsa-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
